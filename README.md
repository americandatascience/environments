# Environments

All GPU-configured environments American Data Science offers with community example notebooks to share.

## AI Environments

- [ai](./ai): Environment equipped with AI tools and SDKs like AlphAI, OpenAI/Anthropic/Cohere SDKs, Scikit Learn, pandas, and numpy.
- [openai](./openai): Environment for OpenAI models and API such as GPT3, ChatGPT, including PyTorch, OpenAI Python library, and Scikit Learn.
- [fastai](./fastai): Environment for Fast.ai tools and PyTorch, ideal for training and running inference on ML models.
- [langchain](./langchain): Environment tailored for working with the Langchain package, including OpenAI libraries and Google tools.
- cohere
- mistral

## Vector Embeddings Environments

- [pinecone](./pinecone): Environment for Pinecone's powerful vector space, including PyTorch, Haystack, Transformers, Cohere, and the OpenAI Python library.
- [modelbit](./modelbit): Environment for the Modelbit package and ecosystem, including modelbit and exploratory packages like sklearn.
- weaviate
- milvus
- chroma
- qdrant

## Deep Learning and Tensor Environments
- torch
- jax
- tensorflow
- [huggingface](./huggingface): Environment optimized for Hugging Face tools like transformers and datasets, powered by PyTorch or Tensorflow.

## Data Analytics Environments
- [rapidsai](./rapidsai): Environment designed for RAPIDS.ai tools like cuDF, cuML, cuGraph, all powered by NVIDIA GPUs.
- ibis

## Chemical Engineering Environments

- [ocp](./ocp): Environment for the Open Catalyst Project's library of state-of-the-art machine learning algorithms for catalysis.
- pymol

## Other Environments

- [minimal](./minimal): A bare-bones Python environment, perfect for starting from scratch.
- [pycse](./pycse): Environment for the pycse python package, ideal for experimenting and learning computational skills with python.
- [latex](./latex): Research environment for live editing and writing in .tex files with the Jupyter Lab LaTeX extension.
- [exploratory](./exploratory): Environment for data exploration and analysis, including tools like Scikit Learn, pandas, and numpy.

## Natural Language Processing Environments

- [spacy](./spacy): Environment for SpaCy, a powerful library for advanced Natural Language Processing (NLP) in Python.
- [nltk](./nltk): Environment for NLTK, a leading platform for building Python programs to work with human language data.
- [gensim](./gensim): Environment for Gensim, a robust open-source vector space modeling and topic modeling toolkit.

## Computer Vision Environments

- [opencv](./opencv): Environment for OpenCV, a library of programming functions mainly aimed at real-time computer vision.
- [pillow](./pillow): Environment for Pillow, a Python Imaging Library that adds image processing capabilities to your Python interpreter.

## Machine Learning Environments

- [xgboost](./xgboost): Environment for XGBoost, a scalable and flexible gradient boosting library.
- [lightgbm](./lightgbm): Environment for LightGBM, a gradient boosting framework that uses tree-based learning algorithms.

## Data Visualization Environments

- [matplotlib](./matplotlib): Environment for Matplotlib, a plotting library for the Python programming language and its numerical mathematics extension NumPy.
- [seaborn](./seaborn): Environment for Seaborn, a Python data visualization library based on Matplotlib.
- [plotly](./plotly): Environment for Plotly, a graphing library makes interactive, publication-quality graphs.
- hvplot
- datashader
- dash
- cuxfilter (in rapidsai)

## Big Data Environments

- [pyspark](./pyspark): Environment for PySpark, the Python library for Apache Spark, an open-source, distributed computing system used for big data processing and analytics.
- [dask](./dask): Environment for Dask, a flexible library for parallel computing in Python.

## Bioinformatics Environments

- [biopython](./biopython): Environment for Biopython, a set of freely available tools for biological computation.
- [bioconductor](./bioconductor): Environment for Bioconductor, a free software project for the analysis and comprehension of genomic data.